{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapilpandey09/NLP/blob/main/Nlp_tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dwVMRtBL8J9",
        "outputId": "47ea16d2-b312-4aae-a23e-82fe9a12c63a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQWmaSzyQ230",
        "outputId": "0f241fa7-83f0-4352-f447-2d3b98b5d611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')   #this will download required data for tokenization\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3boKi7_3RTGB",
        "outputId": "8eb5f610-589d-40c0-f61a-fcd829919dda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hello, welcome tothe world of NLP.\n",
            "It is a very intersting World! Amazing to be here\n"
          ]
        }
      ],
      "source": [
        "corpus= \"\"\" Hello, welcome tothe world of NLP.\n",
        "It is a very intersting World! Amazing to be here\"\"\"\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "vgLA7NOuRlNz"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "# paragraph to senetnce\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ujsP8podSsFH"
      },
      "outputs": [],
      "source": [
        "\n",
        "document = sent_tokenize(corpus)\n",
        "# document as sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i02uzGuKS1De",
        "outputId": "90202155-9a73-46bf-a5e1-c51f1eebbab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' Hello, welcome tothe world of NLP.', 'It is a very intersting World!', 'Amazing to be here']\n"
          ]
        }
      ],
      "source": [
        "print(document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOWbCBtmTtis",
        "outputId": "0d8aece9-66b2-4450-8104-c7fc8738e3c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hello, welcome tothe world of NLP.\n",
            "It is a very intersting World!\n",
            "Amazing to be here\n"
          ]
        }
      ],
      "source": [
        "for i in document:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "H7YqHUkuVDwv"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "# sentences to words\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for document in document:\n",
        "  print(word_tokenize(document))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuiwedH6WEGH",
        "outputId": "f81ac576-5128-4081-c721-50efc475d9d0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'welcome', 'tothe', 'world', 'of', 'NLP', '.']\n",
            "['It', 'is', 'a', 'very', 'intersting', 'World', '!']\n",
            "['Amazing', 'to', 'be', 'here']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize"
      ],
      "metadata": {
        "id": "IONugkpEWGCD"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordpunct_tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVQoOPjArkiY",
        "outputId": "90df92e0-d593-4ff3-e1eb-3be2eebd93a7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " ',',\n",
              " 'welcome',\n",
              " 'tothe',\n",
              " 'world',\n",
              " 'of',\n",
              " 'NLP',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'a',\n",
              " 'very',\n",
              " 'intersting',\n",
              " 'World',\n",
              " '!',\n",
              " 'Amazing',\n",
              " 'to',\n",
              " 'be',\n",
              " 'here']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"\"\" right-hand counterpart of each of the left-hand questions is very likely to be\n",
        "evoked and very easily answered. Your feelings about dolphins and\n",
        "financial crooks, your current mood, your impressions of the political skill of\n",
        "the primary candidate, or the current standing of the president will readily\n",
        "come to mind. The heuristic questions provide an off-the-shelf answer to\n",
        "each of the difficult target questions. Something is still missing from this story: the answers need to be fitted\n",
        "to the original questions. For example, my feelings about dying dolphins must be expressed in dollars. Another capability of System 1, intensity matching, is available to solve that problem. Recall that both feelings and\n",
        "contribution dollars are intensity scales. I can feel more or less strongly\n",
        "about dolphins and there is a contribution that matches the intensity of my\n",
        "feelings. The dollar amount that will come to my mind is the matching\n",
        "amount. Similar intensity matches are possible for all the questions. For\n",
        "example, the political skills of a candidate can range from pathetic to\n",
        "extraordinarily impressive, and the scale of political success can range\n",
        "from the low of “She will be defeated in the primary” to a high of “She will\n",
        "someday be president of the United States.”\n",
        "The automatic processes of the mental shotgun and intensity matching\n",
        "often make available one or more answers to easy questions that could be mapped onto the target question. On some occasions, substitution will\n",
        "occur and a heuristic answer will be endorsed by System 2. Of course, System 2 has the opportunity to reject this intuitive answer, or to modify it\n",
        "by incorporating other information. However, a lazy System 2 often follows\n",
        "the path of least effort and endorses a heuristic answer without much\n",
        "scrutiny of whether it is truly appropriate. You will not be stumped, you will\n",
        "not have to work very her р wheard, and you may not even notice that you\n",
        "did not answer the question you were asked. Furthermore, you may not\n",
        "realize that the target question was difficult, because an intuitive answer to\n",
        "it came readily to mind.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Plc0KRaGrom3"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "UE5o81ELr77X"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "PXrL6NuMzVb6"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNYy8kSzzdZJ",
        "outputId": "32bd8596-15b4-45a7-d7d6-a2217cc16f29"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' right-hand counterpart of each of the left-hand questions is very likely to be\\nevoked and very easily answered.', 'Your feelings about dolphins and\\nfinancial crooks, your current mood, your impressions of the political skill of\\nthe primary candidate, or the current standing of the president will readily\\ncome to mind.', 'The heuristic questions provide an off-the-shelf answer to\\neach of the difficult target questions.', 'Something is still missing from this story: the answers need to be fitted\\nto the original questions.', 'For example, my feelings about dying dolphins must be expressed in dollars.', 'Another capability of System 1, intensity matching, is available to solve that problem.', 'Recall that both feelings and\\ncontribution dollars are intensity scales.', 'I can feel more or less strongly\\nabout dolphins and there is a contribution that matches the intensity of my\\nfeelings.', 'The dollar amount that will come to my mind is the matching\\namount.', 'Similar intensity matches are possible for all the questions.', 'For\\nexample, the political skills of a candidate can range from pathetic to\\nextraordinarily impressive, and the scale of political success can range\\nfrom the low of “She will be defeated in the primary” to a high of “She will\\nsomeday be president of the United States.”\\nThe automatic processes of the mental shotgun and intensity matching\\noften make available one or more answers to easy questions that could be mapped onto the target question.', 'On some occasions, substitution will\\noccur and a heuristic answer will be endorsed by System 2.', 'Of course, System 2 has the opportunity to reject this intuitive answer, or to modify it\\nby incorporating other information.', 'However, a lazy System 2 often follows\\nthe path of least effort and endorses a heuristic answer without much\\nscrutiny of whether it is truly appropriate.', 'You will not be stumped, you will\\nnot have to work very her р wheard, and you may not even notice that you\\ndid not answer the question you were asked.', 'Furthermore, you may not\\nrealize that the target question was difficult, because an intuitive answer to\\nit came readily to mind.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzrKb56mzgTx",
        "outputId": "349ec2e4-ff87-4dca-af57-d3e0e938e41c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4rad5-_z1kA",
        "outputId": "535e7ea9-ae20-4485-cc00-01efb18525c3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import stopwords\n",
        "stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXZWV6uo0DOg",
        "outputId": "3a210cbd-8f61-4caf-d08c-03d2c6ae841b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " \"he's\",\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " 'if',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " \"i've\",\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " \"should've\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " \"we've\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " 'your',\n",
              " \"you're\",\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " \"you've\"]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "xsLJ2zUU0MBw"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "for i in range(len(sentences)):\n",
        "  words = nltk.word_tokenize(sentences[i])\n",
        "  words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentences[i] = ''.join(words)\n",
        "\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATLXwtzE0eyn",
        "outputId": "7eb22d9e-1055-44df-d8a8-f6904f0c8185"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['right-handcounterpartleft-handquestionlikeevokeasiliansw-..', 'yourfeeldolphinfinancicrook-.,.-currentmood-.,.-impresspolitskillprimaricandid-.,.-currentstandpresidreadilicomemind-..', 'theheuristquestionprovidoff-the-shelfanswerdifficulttargetquest-..', 'somethstillmissstori-.:.-answerneedfitoriginquest-..', 'forexampl-.,.-feeldiedolphinmustexpressdollar-..', 'anothcapablsystem1-.,.-intensmatch-.,.-availsolvproblem-..', 'recalfeelcontributdollarintenssc-..', 'ifeellessstronglidolphincontributmatchintensfeel-..', 'thedollaramountcomemindmatchamount-..', 'similarintensmatchpossiblquest-..', 'forexampl-.,.-politskillcandidrangpathetextraordinariliimpress-.,.-scalepolitsuccessranglow-.“.-shedefeatprimari-.”.-high-.“.-shesomedaypresidunitst-.-.”.-theautomatprocessmentalshotgunintensmatchoftenmakeavailoneanswereasiquestioncouldmapontotargetquest-..', 'onocca-.,.-substitutoccurheuristanswerendorssystem2-..', 'ofcour-.,.-system2opportunrejectintuitansw-.,.-modifiincorporinform-..', 'howev-.,.-lazisystem2oftenfollowpathleasteffortendorsheuristanswerwithoutmuchscrutiniwhethertruliappropri-..', 'youstump-.,.-workрwheard-.,.-mayevennoticanswerquestionask-..', 'furthermor-.,.-mayrealiztargetquestiondifficult-.,.-intuitanswercamereadilimind-..']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtZnnXQl1fzK",
        "outputId": "f605a949-ac1f-4399-fbe8-2ddd1760a7cc"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  words = nltk.word_tokenize(sentences[i])\n",
        "  words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentences[i] = ''.join(words)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqjq7tfA38Qy",
        "outputId": "4f6c7f3f-0a3c-4840-82bc-3a4f287a58bd"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['right-handcounterpartleft-handquestionlikeevokeasiliansw-..', 'yourfeeldolphinfinancicrook-.,.-currentmood-.,.-impresspolitskillprimaricandid-.,.-currentstandpresidreadilicomemind-..', 'theheuristquestionprovidoff-the-shelfanswerdifficulttargetquest-..', 'somethstillmissstori-.:.-answerneedfitoriginquest-..', 'forexampl-.,.-feeldiedolphinmustexpressdollar-..', 'anothcapablsystem1-.,.-intensmatch-.,.-availsolvproblem-..', 'recalfeelcontributdollarintenssc-..', 'ifeellessstronglidolphincontributmatchintensfeel-..', 'thedollaramountcomemindmatchamount-..', 'similarintensmatchpossiblquest-..', 'forexampl-.,.-politskillcandidrangpathetextraordinariliimpress-.,.-scalepolitsuccessranglow-.“.-shedefeatprimari-.”.-high-.“.-shesomedaypresidunitst-.-.”.-theautomatprocessmentalshotgunintensmatchoftenmakeavailoneanswereasiquestioncouldmapontotargetquest-..', 'onocca-.,.-substitutoccurheuristanswerendorssystem2-..', 'ofcour-.,.-system2opportunrejectintuitansw-.,.-modifiincorporinform-..', 'howev-.,.-lazisystem2oftenfollowpathleasteffortendorsheuristanswerwithoutmuchscrutiniwhethertruliappropri-..', 'youstump-.,.-workрwheard-.,.-mayevennoticanswerquestionask-..', 'furthermor-.,.-mayrealiztargetquestiondifficult-.,.-intuitanswercamereadilimind-..']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kKwPdKAI5s-J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzxIw4+G+gGzSv+EKNQrgf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}